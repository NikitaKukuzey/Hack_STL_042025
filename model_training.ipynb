{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627e2e0-87bd-4661-b076-d61a8e41ac8f",
   "metadata": {
    "id": "a627e2e0-87bd-4661-b076-d61a8e41ac8f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18c48c-170f-4dec-9cf7-9b9619fe25cc",
   "metadata": {
    "id": "0b18c48c-170f-4dec-9cf7-9b9619fe25cc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('ptrain_v1.csv', encoding='utf-8').set_index('index')\n",
    "test_df  = pd.read_csv('ptest_v1.csv',  encoding='utf-8').set_index('index')\n",
    "\n",
    "doc_emb = pd.read_csv('doc_emb_norm_old.csv',    index_col=0)\n",
    "lsa200  = pd.read_csv('text_data_lsa200.csv',   index_col='index')\n",
    "lsa300  = pd.read_csv('text_data_lsa300.csv',   index_col='index')\n",
    "lsa200_old  = pd.read_csv('text_data_lsa200_old.csv',   index_col='index')\n",
    "lsa300_old  = pd.read_csv('text_data_lsa300_old.csv',   index_col='index')\n",
    "doc_emb_old = pd.read_csv('doc_emb_norm.csv',    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0792ba1-1f77-4023-b867-994e32723a1a",
   "metadata": {
    "id": "e0792ba1-1f77-4023-b867-994e32723a1a",
    "outputId": "e1ddf591-ae8e-4da6-8595-b50636827925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes:\n",
      "  исходный: (247972, 1851)\n",
      "  + doc_emb: (274446, 300)\n",
      "  + lsa200:  (274446, 200)\n",
      "  + lsa300:  (274446, 300)\n",
      "Готово! Сохранены:\n",
      "  • train_full_features.csv\n",
      "  • test_full_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Объединим все признаки по индексу\n",
    "\n",
    "lsa300.columns = [col.replace('lsa_', 'lsa300_') for col in lsa300.columns]\n",
    "lsa200_old.columns = [col.replace('lsa_', 'lsa200_old') for col in lsa200_old.columns]\n",
    "lsa300_old.columns = [col.replace('lsa_', 'lsa300_old') for col in lsa300_old.columns]\n",
    "doc_emb_old.columns = [col.replace('emb_', 'emb_old') for col in doc_emb_old.columns]\n",
    "\n",
    "train_full = train_df.join([doc_emb,doc_emb_old, lsa200, lsa300,lsa200_old,lsa300_old], how='left')\n",
    "test_full  = test_df .join([doc_emb,doc_emb_old, lsa200, lsa300,lsa200_old,lsa300_old], how='left')\n",
    "\n",
    "print(\"Train shapes:\")\n",
    "print(\"  исходный:\", train_df.shape)\n",
    "print(\"  + doc_emb:\", doc_emb.shape)\n",
    "print(\"  + lsa200: \", lsa200.shape)\n",
    "print(\"  + lsa300: \", lsa300.shape)\n",
    "#print(\"  → итоговый:\", train_full.shape, \"\\n\")\n",
    "\n",
    "#print(\"Test shapes:\")\n",
    "#print(\"  исходный:\", test_df.shape)\n",
    "#print(\"  → итоговый:\", test_full.shape, \"\\n\")\n",
    "\n",
    "# 5. Сохраним итоговые файлы\n",
    "#joblib.dump(train_full, 'train_full_features.joblib')\n",
    "#joblib.dump(test_full, 'test_full_features.joblib')\n",
    "\n",
    "#train_full.reset_index().to_csv('train_full_features.csv', index=False)\n",
    "#test_full .reset_index().to_csv('test_full_features.csv',  index=False)\n",
    "\n",
    "print(\"Готово! Сохранены:\")\n",
    "print(\"  • train_full_features.csv\")\n",
    "print(\"  • test_full_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34ff05-5d0e-478a-bbc0-add171bfb6bc",
   "metadata": {
    "id": "cb34ff05-5d0e-478a-bbc0-add171bfb6bc",
    "outputId": "e8e79a3e-f278-455f-8bcb-469ab937377f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del doc_emb\n",
    "del lsa200\n",
    "del lsa300\n",
    "del lsa200_old\n",
    "del lsa300_old\n",
    "del doc_emb_old\n",
    "del train_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80c13f-51c3-4405-a850-b7f22fc98273",
   "metadata": {
    "id": "ac80c13f-51c3-4405-a850-b7f22fc98273"
   },
   "outputs": [],
   "source": [
    "\n",
    "#joblib.dump((X, y, train_idx), r'F:\\train_data.joblib')\n",
    "#joblib.dump((X_test, test_idx), r'F:\\test_data.joblib')\n",
    "#print('Saved train_data.joblib and test_data.joblib in data/ directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f5cf1-1b6c-4947-a0be-25c4f12d0900",
   "metadata": {
    "id": "b03f5cf1-1b6c-4947-a0be-25c4f12d0900"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede8807-c28a-4397-8773-5fd85dc0a625",
   "metadata": {
    "id": "3ede8807-c28a-4397-8773-5fd85dc0a625"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bf596-2753-4608-94ad-4a93dd2d4b6c",
   "metadata": {
    "id": "8c2bf596-2753-4608-94ad-4a93dd2d4b6c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c50f12-20e9-4262-8bdd-bd02cdb5c32b",
   "metadata": {
    "id": "82c50f12-20e9-4262-8bdd-bd02cdb5c32b"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "if 'index' in train_full.columns:\n",
    "    train_full = train_full.set_index('index')\n",
    "idx = train_full.index\n",
    "y   = train_full['target'].values if 'target' in train_full.columns else None\n",
    "train_full  = train_full.drop(columns=['target','Unnamed: 0'], errors='ignore')\n",
    "\n",
    "X = (\n",
    "        train_full\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "        .fillna(0)\n",
    "        .astype(np.float32)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae10231-4176-444a-b716-588e0188ba8d",
   "metadata": {
    "id": "2ae10231-4176-444a-b716-588e0188ba8d",
    "outputId": "21d9916a-415a-474e-fa3d-eb1cbd58e13d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2e77b-2b04-4183-a34c-8bcbc1049187",
   "metadata": {
    "id": "9fe2e77b-2b04-4183-a34c-8bcbc1049187",
    "outputId": "829ec898-751d-4f28-f683-6e859bb05232"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=18)\n",
    "del X\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4d213-62a4-478a-90a5-6d657959a127",
   "metadata": {
    "id": "baf4d213-62a4-478a-90a5-6d657959a127"
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=True)\n",
    "\n",
    "catboost_model = CatBoostClassifier(iterations=10000, depth=8, learning_rate=0.03, loss_function='Logloss', verbose=100, task_type=\"GPU\", devices='0')\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.06, max_depth=10, min_data_in_leaf=10, metric=\"auc\", verbosity=1, device='gpu', gpu_platform_id=0, gpu_device_id=0, num_threads=4)\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.03, max_depth=8, objective='binary:logistic', tree_method=\"hist\", device=\"cuda\", verbosity=2)\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('catboost', catboost_model), ('lgbm', lgb_model), ('xgb', xgb_model)],\n",
    "    final_estimator=meta_model,\n",
    "    cv=StratifiedKFold(n_splits=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370d873-47d1-405e-ad36-cfa001fcb9a2",
   "metadata": {
    "scrolled": true,
    "id": "1370d873-47d1-405e-ad36-cfa001fcb9a2",
    "outputId": "350ad6b2-de96-43b6-cfa3-b293ec7e590d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:45] INFO: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\simple_dmatrix.cc:139: Generating new Ellpack page.\n",
      "[23:16:10] INFO: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\simple_dmatrix.cc:139: Generating new Ellpack page.\n",
      "[23:17:36] INFO: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\simple_dmatrix.cc:139: Generating new Ellpack page.\n",
      "[23:19:29] INFO: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\simple_dmatrix.cc:139: Generating new Ellpack page.\n",
      "[23:21:49] INFO: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\simple_dmatrix.cc:139: Generating new Ellpack page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 6297 Total: 10239.375\n",
      "Warning: less than 75% GPU memory available for training. Free: 6297 Total: 10239.375\n",
      "Warning: less than 75% GPU memory available for training. Free: 6297 Total: 10239.375\n",
      "Warning: less than 75% GPU memory available for training. Free: 6297 Total: 10239.375\n",
      "Warning: less than 75% GPU memory available for training. Free: 6297 Total: 10239.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 2538, number of negative: 185920\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 567313\n",
      "[LightGBM] [Info] Number of data points in the train set: 188458, number of used features: 3448\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1870 dense feature groups (336.45 MB) transferred to GPU in 0.154133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013467 -> initscore=-4.293940\n",
      "[LightGBM] [Info] Start training from score -4.293940\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.664005\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 2538, number of negative: 185920\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 567549\n",
      "[LightGBM] [Info] Number of data points in the train set: 188458, number of used features: 3448\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1866 dense feature groups (335.73 MB) transferred to GPU in 0.139425 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013467 -> initscore=-4.293940\n",
      "[LightGBM] [Info] Start training from score -4.293940\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.642661\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 2538, number of negative: 185920\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 567279\n",
      "[LightGBM] [Info] Number of data points in the train set: 188458, number of used features: 3448\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1868 dense feature groups (335.73 MB) transferred to GPU in 0.175136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013467 -> initscore=-4.293940\n",
      "[LightGBM] [Info] Start training from score -4.293940\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's auc: 0.658011\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 2539, number of negative: 185920\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 567478\n",
      "[LightGBM] [Info] Number of data points in the train set: 188459, number of used features: 3448\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1867 dense feature groups (335.73 MB) transferred to GPU in 0.173587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013472 -> initscore=-4.293546\n",
      "[LightGBM] [Info] Start training from score -4.293546\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.662237\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 2539, number of negative: 185920\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 567651\n",
      "[LightGBM] [Info] Number of data points in the train set: 188459, number of used features: 3448\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1870 dense feature groups (336.45 MB) transferred to GPU in 0.150025 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013472 -> initscore=-4.293546\n",
      "[LightGBM] [Info] Start training from score -4.293546\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid_0's auc: 0.654468\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Матрицы для стекинга\n",
    "S_train = np.zeros((X_train.shape[0], 3))\n",
    "S_test_folds = np.zeros((X_test.shape[0], 3, n_splits))\n",
    "\n",
    "for i, (name, model) in enumerate([\n",
    "    ('xgb',      xgb_model),\n",
    "    ('catboost', catboost_model),\n",
    "    ('lgbm',     lgb_model)\n",
    "]):\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr, y_tr = X_train.iloc[tr_idx], y_train[tr_idx]\n",
    "        X_val, y_val = X_train.iloc[val_idx],   y_train[val_idx]\n",
    "\n",
    "        if name == 'xgb':\n",
    "            # низкоуровневый train для XGBoost\n",
    "            params    = model.get_xgb_params()\n",
    "            num_round = model.get_params()['n_estimators']\n",
    "            dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "            deval  = xgb.DMatrix(X_val, label=y_val)\n",
    "            bst = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=num_round,\n",
    "                evals=[(deval, 'eval')],\n",
    "                early_stopping_rounds=300,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "            # OOF-прогноз и тестовый прогноз\n",
    "            S_train[val_idx, i]      = bst.predict(deval)\n",
    "            S_test_folds[:, i, fold] = bst.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "        else:\n",
    "            # CatBoost или LightGBM — клонируем модель\n",
    "            m = clone(model)\n",
    "            if name == 'catboost':\n",
    "                fit_kwargs = dict(\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=700,\n",
    "                    use_best_model=True,\n",
    "                    verbose=False\n",
    "                )\n",
    "            else:  # lgbm\n",
    "                fit_kwargs = dict(\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric='auc',\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=300)]\n",
    "                )\n",
    "            m.fit(X_tr, y_tr, **fit_kwargs)\n",
    "            S_train[val_idx, i]      = m.predict_proba(X_val)[:, 1]\n",
    "            S_test_folds[:, i, fold] = m.predict_proba(X_test)[:, 1]\n",
    "        gc.collect()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89625aa-f0bf-49e9-9b60-b12be8841e4e",
   "metadata": {
    "id": "d89625aa-f0bf-49e9-9b60-b12be8841e4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2c3c5-1060-4083-a26f-16215a4dd242",
   "metadata": {
    "id": "37f2c3c5-1060-4083-a26f-16215a4dd242",
    "outputId": "0c2dcb98-a2d2-46ea-d15a-2b4834adebb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.joblib']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bb4ae-745a-4aba-9dda-00df366b91d8",
   "metadata": {
    "id": "6a1bb4ae-745a-4aba-9dda-00df366b91d8",
    "outputId": "5d8625c1-ffd2-40aa-a798-5b99b92e7653"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'max_iter' for estimator RandomForestClassifier(max_depth=3, n_estimators=200, n_jobs=-1,\n                       random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[157], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# усредняем прогнозы на тесте по всем фолдам\u001B[39;00m\n\u001B[0;32m      2\u001B[0m S_test \u001B[38;5;241m=\u001B[39m S_test_folds\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m meta_model\u001B[38;5;241m.\u001B[39mset_params(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2000\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 3) Обучаем мета-модель на OOF-фичах\u001B[39;00m\n\u001B[0;32m      5\u001B[0m meta_model\u001B[38;5;241m.\u001B[39mfit(S_train, y_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:283\u001B[0m, in \u001B[0;36mBaseEstimator.set_params\u001B[1;34m(self, **params)\u001B[0m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m valid_params:\n\u001B[0;32m    282\u001B[0m     local_valid_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_param_names()\n\u001B[1;32m--> 283\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    284\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for estimator \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    285\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValid parameters are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlocal_valid_params\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    286\u001B[0m     )\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m delim:\n\u001B[0;32m    289\u001B[0m     nested_params[key][sub_key] \u001B[38;5;241m=\u001B[39m value\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter 'max_iter' for estimator RandomForestClassifier(max_depth=3, n_estimators=200, n_jobs=-1,\n                       random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "# усредняем прогнозы на тесте по всем фолдам\n",
    "S_test = S_test_folds.mean(axis=2)\n",
    "meta_model.set_params(max_iter=2000)\n",
    "# обучаем мета-модель на OOF-фичах\n",
    "meta_model.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30b0a6-af86-43c9-92ad-01881c470348",
   "metadata": {
    "id": "1e30b0a6-af86-43c9-92ad-01881c470348"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73facc98-8083-483f-a6ca-f5922a4880c1",
   "metadata": {
    "id": "73facc98-8083-483f-a6ca-f5922a4880c1",
    "outputId": "ad70fee6-484d-44b7-c8cc-bcc68e057a03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta_model.joblib']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(meta_model,'meta_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5f4bd-6c41-4888-b0c6-bee7ea205ab9",
   "metadata": {
    "id": "67b5f4bd-6c41-4888-b0c6-bee7ea205ab9",
    "outputId": "7d8a2ed0-88da-47d4-d1a1-83ee42c60740"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S_train.joblib']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(S_train,'S_train.joblib')\n",
    "joblib.dump(y_train,'S_train.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b73a8-d464-40da-9dd3-3830baad400f",
   "metadata": {
    "id": "c63b73a8-d464-40da-9dd3-3830baad400f",
    "outputId": "168b872b-c19f-45a1-8955-a5904faad056"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 6297 Total: 10239.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 3173, number of negative: 232400\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 568330\n",
      "[LightGBM] [Info] Number of data points in the train set: 235573, number of used features: 3448\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1868 dense feature groups (419.66 MB) transferred to GPU in 0.149103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013469 -> initscore=-4.293783\n",
      "[LightGBM] [Info] Start training from score -4.293783\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's auc: 0.639464\n",
      "[01:35:04] INFO: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\simple_dmatrix.cc:139: Generating new Ellpack page.\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "catboost_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=700,\n",
    "    use_best_model=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=300)]\n",
    ")\n",
    "\n",
    "# XGBoost — переобучаем через xgb.train, чтобы был Booster с ранней остановкой\n",
    "params    = xgb_model.get_xgb_params()\n",
    "num_round = xgb_model.get_params()['n_estimators']\n",
    "dtrain    = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest     = xgb.DMatrix(X_test,  label=y_test)\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_round,\n",
    "    evals=[(dtest, 'eval')],\n",
    "    early_stopping_rounds=300,\n",
    "    verbose_eval=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f3884-3dbb-4741-9833-bafedfb5ad58",
   "metadata": {
    "id": "f80f3884-3dbb-4741-9833-bafedfb5ad58",
    "outputId": "343089fb-f7d7-416e-8b6b-ab8ec8419c9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.joblib']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(catboost_model,'catboost_model.joblib')\n",
    "joblib.dump(lgb_model,'lgb_model.joblib')\n",
    "joblib.dump(xgb_model,'xgb_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fab6da-502a-47da-afa6-7e7dd3e617b6",
   "metadata": {
    "id": "d0fab6da-502a-47da-afa6-7e7dd3e617b6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Сохраняем список имен колонок сразу после загрузки train:\n",
    "feature_names = X_train.columns.tolist() if hasattr(X_train, \"columns\") else None\n",
    "\n",
    "def stacking_predict_proba(X):\n",
    "    # 1) Приведём X к двум видам: numpy-массиву и DataFrame с нужными именами\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_df = X.copy()\n",
    "        X_arr = X_df.values\n",
    "    else:\n",
    "        X_arr = X\n",
    "        X_df = pd.DataFrame(X_arr, columns=feature_names) if feature_names else None\n",
    "\n",
    "    # 2) Предсказания CatBoost и LightGBM всегда на DataFrame, чтобы сохранить имена\n",
    "    p_cat = catboost_model.predict_proba(X_df if X_df is not None else X_arr)[:, 1]\n",
    "    p_lgb = lgb_model.predict_proba(X_df if X_df is not None else X_arr)[:, 1]\n",
    "\n",
    "    # 3) XGBoost — через DMatrix, отключаем жёсткую валидацию имён\n",
    "    dmat = xgb.DMatrix(X_arr)\n",
    "    p_xgb = xgb_model.predict(dmat, validate_features=False)\n",
    "\n",
    "    # 4) Собираем фичи и предсказываем через мета-модель\n",
    "    feats = np.column_stack([p_cat, p_lgb, p_xgb])\n",
    "    return meta_model.predict_proba(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792004dd-1389-457a-bd69-96b216bd83c7",
   "metadata": {
    "id": "792004dd-1389-457a-bd69-96b216bd83c7",
    "outputId": "304eaace-a909-4a74-c3de-89b5fe3f672f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = stacking_predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719341ca-3ae5-44af-a386-2d7e477303d3",
   "metadata": {
    "id": "719341ca-3ae5-44af-a386-2d7e477303d3",
    "outputId": "638d970e-13b1-40e3-c0e1-bc502a47aad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out AUC: 0.6671693226507708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# y_pred_proba is shape (n_samples, 2)\n",
    "# take only the positive-class probabilities:\n",
    "pos_probs = y_pred_proba[:, 1]\n",
    "\n",
    "print(\"Hold-out AUC:\", roc_auc_score(y_test, pos_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3775d-932a-4e1f-b14f-d084a01f8d7a",
   "metadata": {
    "id": "daa3775d-932a-4e1f-b14f-d084a01f8d7a",
    "outputId": "c09d1d94-9ac6-45e1-979b-3a977135b37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00269792 0.00770806 0.00894657]\n",
      " [0.00979176 0.01205127 0.01105827]\n",
      " [0.00244878 0.00193523 0.00695069]\n",
      " ...\n",
      " [0.02505243 0.0278228  0.02376606]\n",
      " [0.00353733 0.00477124 0.00578646]\n",
      " [0.00868134 0.01154252 0.01351558]]\n"
     ]
    }
   ],
   "source": [
    "print(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252278f4-ec70-45e8-b982-09bbaabffeff",
   "metadata": {
    "id": "252278f4-ec70-45e8-b982-09bbaabffeff"
   },
   "outputs": [],
   "source": [
    "# Обучение мета-модели\n",
    "#stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for ROC-AUC evaluation\n",
    "#y_pred_proba = stacking_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "#roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "#print(f'ROC-AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Make final predictions\n",
    "#y_pred = stacking_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1f335-bfd5-4946-9348-41d51e1bf0b3",
   "metadata": {
    "id": "70b1f335-bfd5-4946-9348-41d51e1bf0b3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d556fb-82f4-46c3-b9d1-ec0e31cbb25d",
   "metadata": {
    "id": "b0d556fb-82f4-46c3-b9d1-ec0e31cbb25d"
   },
   "outputs": [],
   "source": [
    "df = test_full\n",
    "\n",
    "if 'index' in df.columns:\n",
    "    df = df.set_index('index')\n",
    "idx = df.index\n",
    "y_test_s   = df['target'].values if 'target' in df.columns else None\n",
    "df  = df.drop(columns=['target','Unnamed: 0'], errors='ignore')\n",
    "\n",
    "X_test_s = (\n",
    "        df\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "        .fillna(0)\n",
    "        .astype(np.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5f8e6-339b-4c8a-9b6b-5f99cb20afbd",
   "metadata": {
    "id": "cae5f8e6-339b-4c8a-9b6b-5f99cb20afbd",
    "outputId": "e22cbb56-f3e6-4dd4-925e-9ab6eb87cf59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_full\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bde31-d44d-404e-b787-02e51ce3b79d",
   "metadata": {
    "id": "2d7bde31-d44d-404e-b787-02e51ce3b79d",
    "outputId": "20624dac-5e51-4068-ef13-ae2ea022443c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_1 = stacking_predict_proba(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9eac2-e68c-4d6f-8865-44bee1823f8c",
   "metadata": {
    "id": "0fe9eac2-e68c-4d6f-8865-44bee1823f8c",
    "outputId": "1b698da0-d27a-45d2-9faa-1dba9b36122a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_pred_5.joblib']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_test_pred_1,'y_test_pred_5.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf5f65-97b0-4aa8-9dfa-1804b8a21de5",
   "metadata": {
    "id": "6fcf5f65-97b0-4aa8-9dfa-1804b8a21de5",
    "outputId": "331060cb-e1bd-478e-b3da-551c1a168483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01039864 0.01593811 0.01290938 ... 0.00977661 0.01152984 0.00977661]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred_1[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895a70c-c099-4fe0-af7a-79719f8c861f",
   "metadata": {
    "id": "8895a70c-c099-4fe0-af7a-79719f8c861f",
    "outputId": "f82193f1-cc5c-43b5-d927-a08f44194080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл submission.csv с колонками [id, target] готов к загрузке на Kaggle.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': X_test_s.index,\n",
    "    'score': y_test_pred_1[:, 1]\n",
    "})\n",
    "\n",
    "submission.to_csv('submission5.csv', index=False)\n",
    "print(\"Файл submission.csv с колонками [id, target] готов к загрузке на Kaggle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11600e-5bdf-42e9-939d-25b55348e8a0",
   "metadata": {
    "id": "7a11600e-5bdf-42e9-939d-25b55348e8a0"
   },
   "outputs": [],
   "source": [
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
